{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Text Analysis\n",
    "An explanation this assignment could be found in the .pdf explanation document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Materials to review for this assignment\n",
    "<h4>From Moodle:</h4> \n",
    "<h5><u>Review the notebooks regarding the following python topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Working with strings</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Text Analysis</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Hebrew text analysis tools (tokenizer, wordnet)</b> (moodle example)<br/>\n",
    "&#x2714; <b>(brief review) All previous notebooks</b><br/>\n",
    "</div> \n",
    "<h5><u>Review the presentations regarding the following topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Text Analysis</b> (lecture presentation)<br/>\n",
    "&#x2714; <b>(brief review) All other presentations</b><br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details Student 1: Ortal Salman | ortalsn@gmail.com\n",
    "\n",
    "# Details Student 2: Null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preceding Step - import modules (packages)\n",
    "This step is necessary in order to use external modules (packages). <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# ------------- visualizations:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "import sklearn\n",
    "from sklearn import preprocessing, metrics, pipeline, model_selection, feature_extraction \n",
    "from sklearn import naive_bayes, linear_model, svm, neural_network, neighbors, tree\n",
    "from sklearn import decomposition, cluster\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ----------------- output and visualizations: \n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text analysis and String manipulation imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# --------- Text analysis and Hebrew text analysis imports:\n",
    "# vectorizers:\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# regular expressions:\n",
    "import re\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - WordNet (for Hebrew)\n",
    "Note: the WordNet is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install Wordnet (for Hebrew) use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net installation:\n",
    "\n",
    "# unmark if you want to use and need to install\n",
    "# !pip install wn\n",
    "# !python -m wn download omw-he:1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net import:\n",
    "\n",
    "# unmark if you want to use:\n",
    "# import wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - hebrew_tokenizer (Tokenizer for Hebrew)\n",
    "Note: the hebrew_tokenizer is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install hebrew_tokenizer use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer installation:\n",
    "\n",
    "# unmark if you want to use and need to install:\n",
    "# !pip install hebrew_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer import:\n",
    "\n",
    "# unmark if you want to use:\n",
    "# import hebrew_tokenizer as ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input files\n",
    "Reading input files for train annotated corpus (raw text data) corpus and for the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'annotated_corpus_for_train.csv'\n",
    "test_filename  = 'corpus_for_test.csv'\n",
    "df_train = pd.read_csv(train_filename, index_col=None, encoding='utf-8')\n",
    "df_test  = pd.read_csv(test_filename, index_col=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new df (the same as we uploaded) so that we have a backup:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = pd.read_csv(train_filename, index_col=None, encoding='utf-8') #train set\n",
    "new_df_test  = pd.read_csv(test_filename, index_col=None, encoding='utf-8') #test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>כשחבר הזמין אותי לחול, לא באמת חשבתי שזה יקרה,...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>לפני שהתגייסתי לצבא עשיתי כל מני מיונים ליחידו...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>מאז שהתחילו הלימודים חלומו של כל סטודנט זה הפנ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>כשהייתי ילד, מטוסים היה הדבר שהכי ריתק אותי. ב...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‏הייתי מדריכה בכפר נוער ומתאם הכפר היינו צריכי...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>לפני כ3 חודשים טסתי לרומא למשך שבוע. טסתי במטו...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>אני כבר שנתיים נשוי והשנה אני ואישתי סוף סוף י...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>השנה התחלנו שיפוץ בדירה שלנו בתל אביב. הדירה ה...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story gender\n",
       "0  כשחבר הזמין אותי לחול, לא באמת חשבתי שזה יקרה,...      m\n",
       "1  לפני שהתגייסתי לצבא עשיתי כל מני מיונים ליחידו...      m\n",
       "2  מאז שהתחילו הלימודים חלומו של כל סטודנט זה הפנ...      f\n",
       "3  כשהייתי ילד, מטוסים היה הדבר שהכי ריתק אותי. ב...      m\n",
       "4  ‏הייתי מדריכה בכפר נוער ומתאם הכפר היינו צריכי...      f\n",
       "5  לפני כ3 חודשים טסתי לרומא למשך שבוע. טסתי במטו...      f\n",
       "6  אני כבר שנתיים נשוי והשנה אני ואישתי סוף סוף י...      m\n",
       "7  השנה התחלנו שיפוץ בדירה שלנו בתל אביב. הדירה ה...      f"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(753, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train set present:\n",
    "df_train.head(8) \n",
    "df_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_example_id</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>כל קיץ אני והמשפחה נוסעים לארצות הברית לוס אנג...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>הגעתי לשירות המדינה אחרי שנתיים כפעיל בתנועת \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>אחת האהבות הגדולות שלי אלו הכלבים שלי ושל אישת...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_example_id                                              story\n",
       "0                0  כל קיץ אני והמשפחה נוסעים לארצות הברית לוס אנג...\n",
       "1                1  הגעתי לשירות המדינה אחרי שנתיים כפעיל בתנועת \"...\n",
       "2                2  אחת האהבות הגדולות שלי אלו הכלבים שלי ושל אישת..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(323, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test set present:\n",
    "df_test.head(3)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your implementation:\n",
    "Write your code solution in the following code-cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before We Start - STEPS!\n",
    "### STEP 1: Cleaning the data 🫧\n",
    "### STEP 2: Vectorizing texts 🖹\n",
    "### STEP 3: Splitting the data ✂️\n",
    "### STEP 4: Training the model 🏃🏽‍♀️\n",
    "### STEP 5: Score evaluation 📈\n",
    "### STEP 6: Implementation on the test-set 👩🏼‍🔬\n",
    "### STEP 7: Prediction 🔮\n",
    "### STEP 8: Video explanation 📷\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 - cleaning the data!\n",
    "In this section were going to 'scrub' the data, meanig fixing or removing incorrect values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing spaces, commas, special chars, non hebrew words:\n",
    "def clean_data(df_series):\n",
    "    for item in df_series.index:\n",
    "        # using the regular-exprassion module:\n",
    "        df_series[\"story\"][item] = re.sub(r'[?!@#$%^&:;*\"]', '', df_series[\"story\"][item]) #delete special chars\n",
    "        df_series[\"story\"][item] = re.sub(r'\\.', '', df_series[\"story\"][item]) #delete '.'\n",
    "        df_series[\"story\"][item] = re.sub(r'\\,', '', df_series[\"story\"][item]) #delete ','\n",
    "        df_series[\"story\"][item] = re.sub(r'\\b[a-zA-Z]+\\b', '', df_series[\"story\"][item]) #delete english words\n",
    "        df_series[\"story\"][item] = re.sub(r'\\d+', '', df_series[\"story\"][item]) #delete any number\n",
    "        df_series[\"story\"][item] = re.sub(r\"'\", '', df_series[\"story\"][item]) #delete ' char\n",
    "        df_series[\"story\"][item] = re.sub(r'-', '', df_series[\"story\"][item]) #delete - char\n",
    "\n",
    "    return df_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>כשחבר הזמין אותי לחול לא באמת חשבתי שזה יקרה פ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>לפני שהתגייסתי לצבא עשיתי כל מני מיונים ליחידו...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>מאז שהתחילו הלימודים חלומו של כל סטודנט זה הפנ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>כשהייתי ילד מטוסים היה הדבר שהכי ריתק אותי בתו...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‏הייתי מדריכה בכפר נוער ומתאם הכפר היינו צריכי...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>אז לפני שנה בדיוק טסתי לאמסטרדם עם שני חברים ט...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>שבוע שעבר העליתי באופן ספונטני רעיון לנסוע עם ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>לפני חודש עברנו לדירה בבית שמש בעקבות משפחתי ה...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>החוויה אותה ארצה לשתף התרחשה לפני כמה חודשים ז...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>פעם כשהייתי בחו ל בקבולומביה כחלק מהטיול שלי ל...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 story gender\n",
       "0    כשחבר הזמין אותי לחול לא באמת חשבתי שזה יקרה פ...      m\n",
       "1    לפני שהתגייסתי לצבא עשיתי כל מני מיונים ליחידו...      m\n",
       "2    מאז שהתחילו הלימודים חלומו של כל סטודנט זה הפנ...      f\n",
       "3    כשהייתי ילד מטוסים היה הדבר שהכי ריתק אותי בתו...      m\n",
       "4    ‏הייתי מדריכה בכפר נוער ומתאם הכפר היינו צריכי...      f\n",
       "..                                                 ...    ...\n",
       "748  אז לפני שנה בדיוק טסתי לאמסטרדם עם שני חברים ט...      m\n",
       "749  שבוע שעבר העליתי באופן ספונטני רעיון לנסוע עם ...      m\n",
       "750  לפני חודש עברנו לדירה בבית שמש בעקבות משפחתי ה...      m\n",
       "751  החוויה אותה ארצה לשתף התרחשה לפני כמה חודשים ז...      f\n",
       "752  פעם כשהייתי בחו ל בקבולומביה כחלק מהטיול שלי ל...      m\n",
       "\n",
       "[753 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'כשחבר הזמין אותי לחול לא באמת חשבתי שזה יקרה פשוט אמרתי לו כן ותיארתי לעצני שזה יתבטל אחרי שבועיים בערך אני מקבל טלפוןם ממנו שומע מצאתי אחלה מקודות שנוטכל טייל בהם ואז הבנתי שזה הולך לקרות התחלתי להתארגןם על דברים ציוד להליכה תיקים בגדים חמים כסף ודרכון מעודכן לאחר תכנונים נפגשנו בשדה הוא הביא לי את אחד מהתיקים שלו (כי לי אין תיק טוב לטיולים) ועלינו למטוס לאיטליה בטיסה עצמה לא הצלחתי לישון היה ילד קטן שבכה כל הדרך מעצבן כשהגענו הלכנו ישר לסוכנות השכרת הרכב ולקחנו את הרכב שהזמנו מראש סיטרואל C בצבע סגול כי זה מה שנשאר חצי קראנו לה עלינו על חצי והתחלנו את המסע לכיוון אגם גארדה השעה הייתה  בערב קצת קריר בחוץ חושך מוות ואין לנו מושג לאן אנחנו נוסעים (רק עם ) בהתחלה התחלנו לחפש מקום לישון בו מצאנו עיירה סמוכה והחלטנו ללכת לשם על הדרך עצרנו בפיצה הםיצה הראשונה באיטליה משם המשכנו לעיירה עצמה ומצאנו אכסנייה די נחמדה שבה עצרנו ללילה בבוקר שלמחורת הוא מצא מסלול טיול על אחד ההרים באזור נסענו לשם (נסיעה של כשעה בערך) התחלנו לעלות עם הרכב לכיוון המסלול הדרך הייתה נופית עצים ויער מכל כיוון עד שבאיזשהו שלב הוא מבקש ממני לעצור ולחנות את הרכב אני שלא ראיתי חניה מסודרת ולא מכיר מסלולי טיולים כאלה לא הבנתי מה הוא רוצה עצרתי את הרכב יצאנו ממנו מסתכלים לכיוון ההר (בדיעבד ההר היה בגובה של  קמ) הוא מצביע לראש ההר ואומר לי רואה את הצלב שם לשם אנחנו מגיעים אמרתי אוקיי איפה ההתחלה הוא אומר לי פה והתחלנו ללכת לכיוון ראש ההר בהתחלה העליה הייתה די תלולה אני אומנם בלי םפחד גבהים אבל כל הזמן דיברתי איתו מה היה קורה אם אם מישהו נופל מה עושים איל מזעיקים עזרה (העייריה הכי קרובה זה שעה נסיעה אני בלי טלפון עם רשת והוא עם חצי כוח) הסכמנו שאם אחד נופל וזאת פציעה קשה עוצרים (כמובן) ומנסים לפנות כמה שאפשר לא קרה לנו כלום לשמחתי לאחר הטיפוס של שעתיים בערךף הגענו לראש ההר הנוף היה מרשים השמיים היו מכוסים בעננים ולא ראינו יותר מידי בהתחלה אבל לאחר כמה דקות השמיים בתבהרו קצת וראינו ממש רחוק אפילו אתץ האוטו שלא גנבו אותו בסוף (שזאת הייתה אחת מהדאגות שלי) לאחר מכן חזרנו לאוטו ונסענו עיירה חדשה במטרה לטייל שוב ואז התחילה הקורונה לא חשבנו שזה יגיע לאזור שלנו אבל עדיין כששמענו על זה בפעם הראשונה קצת צחקנו ואמרנו שאין סיכוי שזה יגיע אלינו אבל כשהגיע אליטליה מצאנו את עצמנו מנסים לחזור כמה שיותר נמהר הביתה בסוף הספקנו לעלות את הטיסה הראשטה מאיטליה לפני שהיא נסגרה המזל היה שהיינו עם מסיכות כבר אז לא נדבקנו'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'בשנה האחרונה למרות שלא היו יותר מידיי דברים לעשות כי קורונה וזה דווקא הצלחתי להוציא משהו טוב בין הסגרים נסענו עם חברים לטיול קמפינג בנהר הירדן של שלושה ימים התארגנו וקנינו הכל מראש כמובן שבעיקר חטיפים כי כל שאר הדברים לא באמת מעניינים היה דיי קפוא אבל בכל זאת החלטנו להיכנס למים זאת הייתה טעות קשה כי חלק מאיתנו חטפו צינון דיי קשוח ברגע שחזרנו הביתה בדך כלל אני לא אוהבת את כל העיניין הזה של לישון בחוץ וחרקים ונמלים בכל מקום אבל את האמת גיליתי שכשעושים את זה עם האנשים הנכונים אז אפשר אפילו להנות מזב קצת התחלנו את הטיול עם מסלול הליכה קצר ללכת זה לא כיף אז פחות נהנתי בשלב הזה אחר כך מצאנו מקום יחסית נורמאלי שאפשר להקים בו את האוהל סידרנו הכל והתחלנו לשבת וסתם לדבר שחכנו לרגע מכל הטלפונים והיינו רק אחד עם השני כולנו כבר הספקנו לשכוח מה זה להיות בלי הטלפון למשך יותר משעה והטיול הזה הזכיר לנו כמה לחבורה הזאת יש מזל שיש לנו אחד את השני כמובן ששתינו וצחקנו חזרנו לילדות ושיחקנו בכל מיני משחקי קופסא שדאגנו להביא מראש והרגשנו באמת עוד פעם כמו ילדים קטנים עוד לפני שהייתה כל הטכנולוגיה של הטלפונים ולפני שכולם היו דבוקים למסכים הלכנו לישון סופר מאוחר בלילה ולמחרת כשקמנו הכנו לעצמנו ארוחת בוקר מטורפת נכנסנו גם להתרענן במים כמובן למרות שהיה ממש ממש קר החלטנו לאסוף את הדברים שלנו ולנסות למצוא מסעדה טובה באיזור כי כבר נהיינו רעבים ודיי סיימנו את כל מה שהבאנו לאכול יום לפני בגלל שהיינו קצת שתויים ואכלנו פשוט בלי הפסקה מצאנו מסעדה ממש חמודה והתיישבנו שם לאכול צהריים אכלנו ממש הרבה יותר מידיי וכנראה היינו צריכים בערך חצי מהכמות שהזמנו אבל דווקא יצא טוב כי יכלנו לקחת את מה שנשאר בטייק אוואי וככה בעצם יהיה לנו כבר אוכל מוכן לאכול בערב השני של הקמפינג שלנו חזרנו לאותו מקום שהיינו בו והקמנו עוד הפעם את האוהלים בילינו את אותו הערב בדיוק כמו הערב הקודם ובוקר אחרי כבר התקפלנו וחזרנו הביתה'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'בתחילת הקורנה באזור הסגר הראשון אני ובת הזוג שלי היינו אמורים לחגוג  שנים של זוגיות אבל מכיוון שהכל היה סגור ולא היה הרבה מה לעשות אז חשבנו שכל אחד יעשה משהו נחמד לשני רק כדי שנוכל לציין את היום הזה כיום מיוחד עבורנו בת הזוג שלי בחרה לעשות משהו באותו היום ואני הייתי אמור לעשות יום אחריה כאשר הגיע היום היא ביקשה ממני לחזור הביתה קצת יותר מאוחר כדי שתוכל לארגן את כל הדברים שרצתה כשאר הגעתי הביתה בסביבות  בערב היא ביקשה שאאסוף אותה וניסע לחוף הים כשאר הגענו לחוף הים היא פתחה שמיכה כל החוף ועשה לי מן פיקניק בים בערב היא הביאה בקבוק יין ואוכל שהיא הכינה לבד ובנוסף הכינה גם קינוח שוקולד מיוחד היה מאוד נחמד באותו היום ושנינו נהנינו כשאר הגיע היום למחרת היא עבדה עד שעה מאוחרת ואז כבר ידעתי מראש שאני מכין לה המבורגר כמו שהיא אוהבת וגם דיברנו על זה הרבה זמן שבא לנו לאכול המבורגר טוב אז יצאתי מוקדם מהעבודה והלכתי לקבציה קנייתי בשר טחון מנתחים טובים מאוד הגעתי הביתה והתחילתי להכין הכל כשאר נכנסה הביתה כבר היו נרות דוקלים ואווירה רומנטית ביקשתי ממנה שתשב שבשולחן ואז מייד הגשתי לה את האוכל וכל הדברים מסביב אכלנו הכל היא אמרה שהיה לה מאוד טעים ונהנתה מאוד יום לאחר מכן אני מקבל שיחה ממנה שהיא נוסעת להורים שלה והיא לא מתכוונת לחזור ושהיא רוצצה להיפרד אני הייץי מופתע מאוד מהדבר בעיקר כשיום קודם הכל היה בסדר וזה פתאום מגיע משום מקום היא ניתקה את השיחה ולא ענתה לי במשך כמה שעות עד שהחלטתי לנסוע לבית הוריה ולהבין מה הסיפור ומה קרה כאשר הגעתי לשם התחלנו לדבר למרות שהיא ממש לא הייתה מעוניינת אבל התעקשתי איתה ולבוסף היא הסכימה מסתבר שכשהיא סיפרה להורים שלה על מה עשיתי לה הם רק אמרו דבברים רעים ושלא מגיע לה והיא צריכה מישהו שיקח אותה לחול וישלם עליה ולא רק שיעשה לה דברים כאלה לבסוף היא הייתה יותר מדי נתונה להשפעת ההורים שלה ורק אחרי מספר ימים הבינה שזו טעות היא חזרה הביתה וביקשה סליחה על העניין ועל איך שיצא'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#my check:\n",
    "clean_data(new_df_train)\n",
    "new_df_train.story[0]\n",
    "new_df_train.story[60]\n",
    "new_df_train.story[700]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see above, our data is cleaner...Now we can create a new train and test set with the cleaned data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = clean_data(new_df_train)\n",
    "new_df_test = clean_data(new_df_test)\n",
    "\n",
    "#-------------copy-----------\n",
    "new_df_train_cp = clean_data(new_df_train).copy()\n",
    "new_df_test_cp = clean_data(new_df_test).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 - splitting the data!\n",
    "In this section were going to split the train set to 2 parts:\n",
    "1. test (0.2)\n",
    "2. train (0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "586    לאחר השחרור מהצבא בשנה האחרונה נפלתי לבור של ר...\n",
       "131    ביום שישי האחרון התקשר אלי חברי הטוב שם בדוי א...\n",
       "44     לפני מספר שנים בהיותי תלמיד תיכון הוטלה עלינו ...\n",
       "70     אנחנו הכרנו לפני  שנים בתקופת הצבא הכרנו דרך ה...\n",
       "581    הגעתי ליום סיירות ב וחיכיתי בטור שביקשו לעמוד ...\n",
       "Name: story, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "586    m\n",
       "131    m\n",
       "44     m\n",
       "70     f\n",
       "581    m\n",
       "Name: gender, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "716    יום אחד במהלך חופשת חנוכה הלכנו כמה חברים לשחק...\n",
       "651    לפני כחצי שנה עברתי לגור בצפון עם בת זוגתי עבר...\n",
       "371    כשהתחילה הקורונה הלימודים עברו להיות רק בזום כ...\n",
       "77     בשנה האחרונה עברתי דירה לעיר שיש בה ים כל חיי ...\n",
       "212    לפני חצי שנה הייתי באיטליה עם המשפחה שלי זאת ה...\n",
       "Name: story, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "716    m\n",
       "651    m\n",
       "371    f\n",
       "77     f\n",
       "212    f\n",
       "Name: gender, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this function will split the data and determain:\n",
    "# df[\"story\"] - input features (X)\n",
    "# df[\"gender\"] - labels (y)\n",
    "\n",
    "def splitting_data(df):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[\"story\"], df[\"gender\"], test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#calling the fun:\n",
    "X_train, X_test, y_train, y_test = splitting_data(new_df_train.copy())\n",
    "X_train_cp, X_test_cp, y_train_cp, y_test_cp = splitting_data(new_df_train.copy())\n",
    "\n",
    "#presenting the data:\n",
    "#train:\n",
    "X_train_cp.head(5)\n",
    "y_train_cp.head(5)\n",
    "#test:\n",
    "X_test_cp.head(5)\n",
    "y_test_cp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 - vectorizing texts!\n",
    "In this section were going to convert out text data to numerical vectors:\n",
    "male - 0\n",
    "female - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we created 2 new columns for female & male: if a text was written by male it would get 1 in the 'gender_m' column:\n",
    "#we changed the strings 'f' & 'm' to numeric values:\n",
    "new_train_cp = pd.get_dummies(new_df_train.copy(), columns=['gender'], prefix=['gender'])\n",
    "\n",
    "#Initialize the TF-IDF vectorizer:\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#Fit and transform the training data:\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_cp)\n",
    "\n",
    "#Transform the testing data:\n",
    "X_test_tfidf = vectorizer.transform(X_test_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4 - training the model!\n",
    "In this section were going to train our model based on a few algorithms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model\n",
    "### This module works effectively on binary classification:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#'?_train_tfidf_copy' writing format represent LR model\n",
    "\n",
    "X_train_tfidf_copy = X_train_tfidf.copy()\n",
    "y_train_copy = y_train_cp.copy()\n",
    "X_test_tfidf_copy = X_test_tfidf.copy()\n",
    "y_test_LG = y_test_cp.copy()\n",
    "\n",
    "#Initialize the logistic regression model\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "#Train the model on the training data\n",
    "logreg_model.fit(X_train_tfidf_copy, y_train_copy)\n",
    "\n",
    "#Make predictions on the testing data\n",
    "logreg_predictions = logreg_model.predict(X_test_tfidf_copy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier: can handle both classification and regression tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#'?_train_tfidf_forest' writing format represent RF model\n",
    "\n",
    "X_train_tfidf_forest = X_train_tfidf.copy()\n",
    "y_train_forest = y_train_cp.copy()\n",
    "X_test_tfidf_forest = X_test_tfidf.copy()\n",
    "y_test_cp_forest = y_test_cp.copy()\n",
    "\n",
    "#Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "#Train the model on the training data\n",
    "rf_classifier.fit(X_train_tfidf_forest, y_train_forest)\n",
    "\n",
    "#Make predictions on the testing data\n",
    "rf_predictions = rf_classifier.predict(X_test_tfidf_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier:  builds multiple weak learners sequentially and focusing on correcting the errors: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#'?_train_tfidf_GBC' writing format represent GBC model\n",
    "\n",
    "X_train_tfidf_GBC = X_train_tfidf.copy()\n",
    "y_train_GBC = y_train_cp.copy()\n",
    "X_test_tfidf_GBC = X_test_tfidf.copy()\n",
    "y_test_cp_GBC = y_test_cp.copy()\n",
    "\n",
    "#Initialize the Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "\n",
    "#Train the model on the training data\n",
    "gb_classifier.fit(X_train_tfidf_GBC, y_train_GBC)\n",
    "\n",
    "#Make predictions on the testing data\n",
    "gb_predictions = gb_classifier.predict(X_test_tfidf_GBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN) Classifier: KNN is a simple algorithm that classifies an object by the majority class of its k nearest neighbors in the training data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#'?_train_tfidf_KNN' writing format represent KNN model\n",
    "\n",
    "X_train_tfidf_KNN = X_train_tfidf.copy()\n",
    "y_train_KNN = y_train_cp.copy()\n",
    "X_test_tfidf_KNN = X_test_tfidf.copy()\n",
    "y_test_cp_KNN = y_test_cp.copy()\n",
    "\n",
    "#Initialize the KNN Classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "#Train the model on the training data\n",
    "knn_classifier.fit(X_train_tfidf_KNN, y_train_KNN)\n",
    "\n",
    "#Make predictions on the testing data\n",
    "knn_predictions = knn_classifier.predict(X_test_tfidf_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM: support vector machine - good at solving binary classification problems, which require classifying the elements of a data set into two groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#'?_train_tfidf_SVM' writing format represent SVM model\n",
    "\n",
    "X_train_tfidf_SVM = X_train_tfidf.copy()\n",
    "y_train_SVM = y_train_cp.copy()\n",
    "X_test_tfidf_SVM = X_test_tfidf.copy()\n",
    "y_test_cp_SVM = y_test_cp.copy()\n",
    "\n",
    "#Initialize the SVM Classifier with a linear kernel\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "#Train the model on the training data\n",
    "svm_classifier.fit(X_train_tfidf_SVM, y_train_SVM)\n",
    "\n",
    "#Make predictions on the testing data\n",
    "svm_predictions = svm_classifier.predict(X_test_tfidf_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5 - score evaluation!\n",
    "In this section were going to evaluate the scores from the previous step - how reliable our models are?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Logistic Regression mdel's performance, our target is min 'macro avg' of 0.6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f       0.00      0.00      0.00        37\n",
      "           m       0.75      1.00      0.86       114\n",
      "\n",
      "    accuracy                           0.75       151\n",
      "   macro avg       0.38      0.50      0.43       151\n",
      "weighted avg       0.57      0.75      0.65       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(y_test_LG, logreg_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Random Forest Classifier model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f       0.00      0.00      0.00        37\n",
      "           m       0.75      1.00      0.86       114\n",
      "\n",
      "    accuracy                           0.75       151\n",
      "   macro avg       0.38      0.50      0.43       151\n",
      "weighted avg       0.57      0.75      0.65       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Classifier:\")\n",
    "print(classification_report(y_test_cp_forest, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Gradient Boosting Classifier model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f       0.71      0.27      0.39        37\n",
      "           m       0.80      0.96      0.88       114\n",
      "\n",
      "    accuracy                           0.79       151\n",
      "   macro avg       0.76      0.62      0.63       151\n",
      "weighted avg       0.78      0.79      0.76       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient Boosting Classifier:\")\n",
    "print(classification_report(y_test_cp_GBC, gb_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the K-Nearest Neighbors Classifier model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f       0.42      0.27      0.33        37\n",
      "           m       0.79      0.88      0.83       114\n",
      "\n",
      "    accuracy                           0.73       151\n",
      "   macro avg       0.60      0.57      0.58       151\n",
      "weighted avg       0.70      0.73      0.71       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"K-Nearest Neighbors Classifier:\")\n",
    "print(classification_report(y_test_cp_KNN, knn_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the SVM model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier (Linear Kernel):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f       0.00      0.00      0.00        37\n",
      "           m       0.75      1.00      0.86       114\n",
      "\n",
      "    accuracy                           0.75       151\n",
      "   macro avg       0.38      0.50      0.43       151\n",
      "weighted avg       0.57      0.75      0.65       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Classifier (Linear Kernel):\")\n",
    "print(classification_report(y_test_cp_SVM, svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see, our scores are not higt enongh:\n",
    " LG-0.43 /\n",
    " RF-0.43 /\n",
    " GBC-0.63 /\n",
    " KNN-0.58 /\n",
    " SVM-0.43\n",
    " \n",
    "So now what?\n",
    "we'll start with the KNN model and try to 'play' with it so we can get higher:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF vectorizing once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.8173913043478261\n",
      "Macro Average F1-score: 0.6170289855072464\n"
     ]
    }
   ],
   "source": [
    "#'vectorizer2' represent the TF-IDF vectorizing from the second time (first time was after the splitting step)\n",
    "\n",
    "#Create TF-IDF vectorizer with stop words removed\n",
    "vectorizer2 = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "\n",
    "#Fit and transform the training data\n",
    "X_train_tfidf2 = vectorizer2.fit_transform(X_train_cp)\n",
    "\n",
    "#Transform the test data using the same vectorizer\n",
    "X_test_tfidf2 = vectorizer2.transform(X_test_cp)\n",
    "\n",
    "#Initialize and train the KNN classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_classifier.fit(X_train_tfidf2, y_train_cp)\n",
    "\n",
    "#Make predictions on the test data\n",
    "knn_predictions = knn_classifier.predict(X_test_tfidf2)\n",
    "\n",
    "#Calculate F1-score\n",
    "f1 = f1_score(y_true=y_test_cp, y_pred=knn_predictions, pos_label='m')\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "#Calculate macro average F1-score\n",
    "f1_macro_avg = f1_score(y_true=y_test_cp, y_pred=knn_predictions, average='macro')\n",
    "print(\"Macro Average F1-score:\", f1_macro_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfortunately out score dropped...let's try again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for Male: 0.8582995951417005\n",
      "F1-score for Female: 0.36363636363636365\n",
      "Average F1-score: 0.6109679793890321\n"
     ]
    }
   ],
   "source": [
    "#Initialize the TF-IDF vectorizer\n",
    "vectorizer3 = TfidfVectorizer() #changed to vectorizer3\n",
    "\n",
    "#Fit and transform the training data\n",
    "X_train_tfidf_knn = vectorizer3.fit_transform(X_train_cp)\n",
    "\n",
    "#Transform the testing data\n",
    "X_test_tfidf_knn = vectorizer.transform(X_test_cp)\n",
    "\n",
    "#Initialize the KNN Classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "#Fit the KNN classifier on the training data\n",
    "knn_classifier.fit(X_train_tfidf_KNN, y_train_cp)\n",
    "\n",
    "#Make predictions using the KNN model\n",
    "knn_predictions = knn_classifier.predict(X_test_tfidf_knn)\n",
    "\n",
    "#Compute F1-score treating 'male' as positive\n",
    "f1_male = f1_score(y_true=y_test_cp, y_pred=knn_predictions, pos_label='m')\n",
    "print(\"F1-score for Male:\", f1_male)\n",
    "\n",
    "#Compute F1-score treating 'female' as positive\n",
    "f1_female = f1_score(y_true=y_test_cp, y_pred=knn_predictions, pos_label='f')\n",
    "print(\"F1-score for Female:\", f1_female)\n",
    "\n",
    "#Calculate the average F1-score\n",
    "average_f1 = (f1_male + f1_female) / 2\n",
    "print(\"Average F1-score:\", average_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nothing really changed...let's take the GBC algo' and 'play' with it:\n",
    "### Since we found the better hyperparameter, let's run the GBC module and hope we get higher score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(max_features=1000)),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             param_grid={'knn__n_neighbors': [3, 5, 7], 'knn__p': [1, 2],\n",
       "                         'knn__weights': ['uniform', 'distance']},\n",
       "             scoring='f1_macro', verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'knn__n_neighbors': 3, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "Best F1-score: 0.5724442274190631\n",
      "K-Nearest Neighbors Classifier (Best Hyperparameters):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f       0.43      0.41      0.42        37\n",
      "           m       0.81      0.82      0.82       114\n",
      "\n",
      "    accuracy                           0.72       151\n",
      "   macro avg       0.62      0.61      0.62       151\n",
      "weighted avg       0.72      0.72      0.72       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline with TF-IDF vectorizer and KNN classifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=1000)), \n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [3, 5, 7],\n",
    "    'knn__p': [1, 2],\n",
    "    'knn__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro', verbose=1)\n",
    "\n",
    "# Fit the GridSearchCV on training data\n",
    "grid_search.fit(X_train_cp, y_train_cp)\n",
    "\n",
    "# Get the best KNN model with optimized hyperparameters\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions using the best KNN model on test data\n",
    "knn_predictions = best_knn_model.predict(X_test_cp)\n",
    "\n",
    "# Print the best hyperparameters and F1-score\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best F1-score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the KNN model's performance\n",
    "print(\"K-Nearest Neighbors Classifier (Best Hyperparameters):\")\n",
    "print(classification_report(y_test_cp, knn_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's a little bit better...let's try harder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the same vectorizing but with the X_train_tfidf2:\n",
    "X_train_tfidf_GBC = X_train_tfidf2.copy()\n",
    "y_train_GBC = y_train_cp.copy()\n",
    "X_test_tfidf_GBC = X_test_tfidf2.copy()\n",
    "y_test_cp_GBC = y_test_cp.copy()\n",
    "\n",
    "# Initialize the Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "\n",
    "# Train the model on the training data\n",
    "gb_classifier.fit(X_train_tfidf_GBC, y_train_GBC)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "gb_predictions = gb_classifier.predict(X_test_tfidf_GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f       0.80      0.32      0.46        37\n",
      "           m       0.82      0.97      0.89       114\n",
      "\n",
      "    accuracy                           0.81       151\n",
      "   macro avg       0.81      0.65      0.67       151\n",
      "weighted avg       0.81      0.81      0.78       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient Boosting Classifier:\")\n",
    "print(classification_report(y_test_cp_GBC, gb_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We improved to 0.67!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6 - implementation on the test-set!\n",
    "In this section were going to give our model the 'real' test - would he make it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(max_features=1000)),\n",
       "                ('knn', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['m', 'm', 'm', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'f', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm',\n",
       "       'f', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'f', 'f', 'm', 'm', 'm', 'f', 'f', 'm', 'm',\n",
       "       'f', 'm', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'f', 'f', 'm', 'm', 'f', 'm', 'f', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'f', 'm', 'f', 'm', 'm', 'f', 'm', 'm', 'f', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'f',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'f', 'm', 'f', 'f', 'm', 'm', 'm', 'f', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=1000)), #changed TfidfVectorizer to vectorizer2\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# fit\n",
    "#X_train, X_test, y_train, y_test = splitting_data(new_df_train.copy())\n",
    "final_model.fit(X_test, y_test)\n",
    "# predict - 0=m , 1=f\n",
    "pred_test_0_1 = final_model.predict(new_df_test.story)\n",
    "pred_test_0_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7 - prediction!\n",
    "In this section were going to present 10 prediction examples (5 head, 5 tail) from out test set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      m\n",
       "1      m\n",
       "2      m\n",
       "3      m\n",
       "4      m\n",
       "      ..\n",
       "318    m\n",
       "319    m\n",
       "320    m\n",
       "321    m\n",
       "322    m\n",
       "Name: pred_catg, Length: 323, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = pd.Series(pred_test_0_1, name='pred_catg').replace({0:'m',1:'f'})\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have come to the end of our journey, all there's left is our video. Enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 8 - video explanation!\n",
    "In this section were going to explain our flow by walking you throght the steps. \n",
    "Link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://youtu.be/PM7vZcRR-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to csv (optional)\n",
    "After you're done save your output to the 'classification_results.csv' csv file.<br/>\n",
    "We assume that the dataframe with your results contain the following columns:\n",
    "* column 1 (left column): 'test_example_id'  - the same id associated to each of the test stories to be predicted.\n",
    "* column 2 (right column): 'predicted_category' - the predicted gender value for each of the associated story. \n",
    "\n",
    "Assuming your predicted values are in the `df_predicted` dataframe, you should save you're results as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.to_csv('classification_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
